% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


\appendix[Model Parameters]

%Table \ref{table:autoencoder_structure} presents the layer configuration and output sizes %of the autoencoder DNN models used in the single-user and multi-user case. Table %\ref{table:covert_models_structure} displays the DNN model structure of the covert actors %and their differences in single-user and multi-user case.

\begin{table*}[!th]
		\caption{Autoencoder's detailed network architecture in the single-user and multi-user case.}
	\begin{adjustbox}{width=1\textwidth,center}
		\begin{tabular}{c|c|c|c|c|c|}
			\cline{2-6}
			& \textbf{UserTX Encoder} & \textbf{UserRX Parameter Estimation} & \textbf{UserRX Decoder} & \textbf{BaseRX  Pre-Decoder} & \textbf{BaseRX Decoders} \\ \hline
			\multicolumn{1}{|c|}{input size} & 16 & 2 $\times$ 16 & 2 $\times$ 8 & $n_{tx} \times$ 2 $\times$ 8 & $n_{tx} \times$ 4 $\times$ 8 \\ \hline
			\multicolumn{1}{|c|}{dense layers sizes} & 2 $\times$ 8, 2 $\times$ 8 & 2 $\times$ 16, 2 $\times$ 32, 2 $\times$ 8 & 2 $\times$ 8, 2 $\times$ 8 & \begin{tabular}[c]{@{}c@{}}$n_{tx} \times$ 2 $\times$ 8, $n_{tx} \times$ 4 $\times$ 8\end{tabular} & $n_{tx} \times$ 2 $\times$ 8 \\ \hline
			\multicolumn{1}{|c|}{dense layers activations} & 2 $\times$ ELU & ELU, 2 $\times$ Tanh & 2 $\times$ Tanh, Softmax & 3 $\times$ Tanh & Tanh, Softmax \\ \hline
			\multicolumn{1}{|c|}{conv filters} & 1, 8, 8, 8 & - & 1, 8, 8, 8 & 1, 8, 8, 8 & - \\ \hline
			\multicolumn{1}{|c|}{conv kernel sizes} & 2, 4, 2, 2 & - & 2, 4, 2, 2 & 2, 4, 2, 2 & - \\ \hline
			\multicolumn{1}{|c|}{conv strides} & 1, 2, 1, 1 & - & 1, 2, 1, 1 & 1, 2, 1, 1 & - \\ \hline
			\multicolumn{1}{|c|}{conv activations} & 4 $\times$ Tanh & - & 4 $\times$ Tanh & 4 $\times$ Tanh & - \\ \hline
			\multicolumn{1}{|c|}{output size} & 2 $\times$ 8 & 2 $\times$ 1 & 16 & $n_{tx} \times$ 4 $\times$ 8 & 16 \\ \hline
		\end{tabular}
	\end{adjustbox}
	\label{table:autoencoder_structure}
\end{table*}

\begin{table}[!th]
		\caption{Alice, Bob, and Willie's detailed network architecture in the single-user and multi-user case.}
	\begin{adjustbox}{width=1\textwidth,center}
		\begin{tabular}{c|c|c|c|c|c|}
			\cline{2-6}
			\multicolumn{1}{l|}{} & \textbf{Alice (Single-User)} & \textbf{Alice (Multi-User) AWGN} & \textbf{Alice (Multi-User) Rayleigh/Rician} & \textbf{Bob} & \textbf{Willie} \\ \hline
			\multicolumn{1}{|c|}{input size} & 16 + $2^{k}$ & 16  + $2^{k}$ & 16  + $2^{k+1}$ + ($n_{tx} \times n_{tx} \times 2$) & 16 & 16 \\ \hline
			\multicolumn{1}{|c|}{dense layers sizes} & \begin{tabular}[c]{@{}c@{}}32  + $2^{k+1}$, \\ 32 + $2^{k+1}$, \\ 8 $\times 2^k$\end{tabular} & \begin{tabular}[c]{@{}c@{}}32  + $2^{k+1}$, \\ 32 + $2^{k+1}$, \\ 8 $\times 2^k$\end{tabular} & \begin{tabular}[c]{@{}c@{}}32  + $2^{k+1}$ + ($n_{tx} \times n_{tx} \times 2$),\\ 32 + $2^{k+1}$, \\ 32 + $2^{k+1}$, \\ 8 $\times 2^k$\end{tabular} & 2 $\times$ 8, 16 & 2 $\times$ 8, 2 $\times$ 8 \\ \hline
			\multicolumn{1}{|c|}{dense layers activations} & 3 $\times$ ReLU, Tanh & 3 $\times$ ReLU, Tanh & 4 $\times$ ReLU, Tanh & 2 $\times$ Tanh, Softmax & 2 $\times$ Tanh, Sigmoid \\ \hline
			\multicolumn{1}{|c|}{conv filters} & - & - & - & 1, 8, 8, 8, 8 & 1, 8, 8, 8, 8 \\ \hline
			\multicolumn{1}{|c|}{conv kernel sizes} & - & - & - & 1, 2, 4, 2, 2 & 1, 2, 4, 2, 2 \\ \hline
			\multicolumn{1}{|c|}{conv strides} & - & - & - & 1, 1, 2, 1, 1 & 1, 1, 2, 1, 1 \\ \hline
			\multicolumn{1}{|c|}{conv activations} & - & - & - &  5 $\times$ LeakyReLU & 5 $\times$ LeakyReLU \\ \hline
			\multicolumn{1}{|c|}{output size} & 2 $\times$ 8 & 2 $\times$ 8 & 2 $\times$ 8 & $2^{k}$ & 1 \\ \hline
		\end{tabular}
	\end{adjustbox}
	\label{table:covert_models_structure}
\end{table}